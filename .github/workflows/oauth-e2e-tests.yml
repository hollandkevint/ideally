name: OAuth E2E Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'apps/web/**'
      - '.github/workflows/oauth-e2e-tests.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'apps/web/**'
      - '.github/workflows/oauth-e2e-tests.yml'
  schedule:
    # Run nightly OAuth validation at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      test_environment:
        description: 'Test environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production
      use_real_oauth:
        description: 'Use real OAuth provider'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '18'
  WORKING_DIRECTORY: apps/web

jobs:
  oauth-e2e-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, Mobile Chrome]
        include:
          - browser: chromium
            project: chromium
          - browser: Mobile Chrome
            project: Mobile Chrome

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: '${{ env.WORKING_DIRECTORY }}/package-lock.json'

      - name: Install dependencies
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: npm ci

      - name: Install Playwright browsers
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: npx playwright install --with-deps

      - name: Validate test environment
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          echo "Validating OAuth test environment configuration..."
          node -e "
            const { testConfig, validateTestEnvironment } = require('./tests/config/test-env.ts');
            const errors = validateTestEnvironment();
            if (errors.length > 0) {
              console.error('❌ Environment validation failed:');
              errors.forEach(error => console.error('  -', error));
              process.exit(1);
            }
            console.log('✅ Environment validation passed');
            console.log('Mock OAuth enabled:', testConfig.oauth.useMockProvider);
          "

      - name: Start application
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          npm run build
          npm run start &
          echo "APP_PID=$!" >> $GITHUB_ENV
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}

      - name: Wait for application to be ready
        run: |
          echo "Waiting for application to start..."
          timeout 120 bash -c 'until curl -f http://localhost:3002/api/health > /dev/null 2>&1; do sleep 2; done' || \
          timeout 120 bash -c 'until curl -f http://localhost:3002 > /dev/null 2>&1; do sleep 2; done'
          echo "Application is ready"

      - name: Run OAuth E2E tests
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: npx playwright test --project="${{ matrix.project }}" --grep="oauth" --reporter=html,json,junit
        env:
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          USE_MOCK_OAUTH: ${{ github.event.inputs.use_real_oauth != 'true' }}
          TEST_OAUTH_CLIENT_ID: ${{ secrets.TEST_OAUTH_CLIENT_ID }}
          TEST_OAUTH_CLIENT_SECRET: ${{ secrets.TEST_OAUTH_CLIENT_SECRET }}
          CI: true

      - name: Generate OAuth test report
        if: always()
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          npx ts-node tests/scripts/generate-oauth-report.ts
          echo "OAuth test report generated"

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: oauth-test-results-${{ matrix.browser }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/playwright-report/
            ${{ env.WORKING_DIRECTORY }}/test-results/
          retention-days: 7

      - name: Upload test report artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: oauth-reports-${{ matrix.browser }}
          path: |
            ${{ env.WORKING_DIRECTORY }}/playwright-report/oauth-*.json
            ${{ env.WORKING_DIRECTORY }}/playwright-report/oauth-*.md
            ${{ env.WORKING_DIRECTORY }}/playwright-report/junit-results.xml
          retention-days: 30

      - name: Stop application
        if: always()
        run: |
          if [ ! -z "$APP_PID" ]; then
            kill $APP_PID 2>/dev/null || true
          fi
          pkill -f "next start" || true

  aggregate-results:
    runs-on: ubuntu-latest
    needs: oauth-e2e-tests
    if: always()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: oauth-*
          merge-multiple: true
          path: aggregated-results/

      - name: Aggregate OAuth test results
        run: |
          echo "Aggregating OAuth test results across browsers..."

          # Count total tests and failures
          total_tests=0
          failed_tests=0

          for report in aggregated-results/oauth-ci-summary.json; do
            if [ -f "$report" ]; then
              tests=$(jq -r '.totalTests // 0' "$report")
              failures=$(jq -r '.failed // 0' "$report")
              total_tests=$((total_tests + tests))
              failed_tests=$((failed_tests + failures))
            fi
          done

          success_rate=$(( (total_tests - failed_tests) * 100 / total_tests ))

          echo "TOTAL_TESTS=$total_tests" >> $GITHUB_ENV
          echo "FAILED_TESTS=$failed_tests" >> $GITHUB_ENV
          echo "SUCCESS_RATE=$success_rate" >> $GITHUB_ENV

          # Determine overall status
          if [ $success_rate -ge 95 ]; then
            echo "OVERALL_STATUS=✅ PASS" >> $GITHUB_ENV
            echo "STATUS_COLOR=success" >> $GITHUB_ENV
          else
            echo "OVERALL_STATUS=❌ FAIL" >> $GITHUB_ENV
            echo "STATUS_COLOR=failure" >> $GITHUB_ENV
          fi

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs')

            // Try to read a summary file
            let summary = {
              status: process.env.OVERALL_STATUS,
              successRate: process.env.SUCCESS_RATE,
              totalTests: process.env.TOTAL_TESTS,
              failed: process.env.FAILED_TESTS,
              recommendation: process.env.SUCCESS_RATE >= 95
                ? '✅ OAuth implementation is ready for deployment'
                : '⚠️ OAuth issues detected - review before deployment'
            }

            try {
              const summaryPath = 'aggregated-results/oauth-ci-summary.json'
              if (fs.existsSync(summaryPath)) {
                const data = fs.readFileSync(summaryPath, 'utf8')
                summary = { ...summary, ...JSON.parse(data) }
              }
            } catch (error) {
              console.log('Using aggregated summary data')
            }

            const comment = `## 🔐 OAuth E2E Test Results

            **Status**: ${summary.status}
            **Success Rate**: ${summary.successRate}%
            **Tests**: ${summary.totalTests} total, ${summary.failed} failed
            **Browsers**: Chrome Desktop + Mobile Chrome

            ### Performance
            ${summary.averageLatency ? `- Average Latency: ${Math.round(summary.averageLatency)}ms` : '- Performance data not available'}

            ### Recommendation
            ${summary.recommendation}

            ${summary.failed > 0 ? `
            ### Next Steps
            - Review failed test artifacts
            - Check OAuth provider configuration
            - Validate environment setup` : ''}

            📊 [View detailed results](https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})`

            // Find existing comment and update or create new
            const { data: comments } = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            })

            const existingComment = comments.find(comment =>
              comment.body.includes('🔐 OAuth E2E Test Results')
            )

            if (existingComment) {
              await github.rest.issues.updateComment({
                comment_id: existingComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              })
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              })
            }

      - name: Create deployment status
        if: github.ref == 'refs/heads/main'
        uses: actions/github-script@v7
        with:
          script: |
            const status = process.env.SUCCESS_RATE >= 95 ? 'success' : 'failure'
            const description = `OAuth E2E: ${process.env.SUCCESS_RATE}% success rate`

            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: status,
              target_url: `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`,
              description: description,
              context: 'OAuth E2E Tests'
            })

      - name: Notify Slack on failure
        if: failure() && (github.ref == 'refs/heads/main' || github.event_name == 'schedule')
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#oauth-alerts'
          title: 'OAuth E2E Tests Failed'
          message: |
            OAuth E2E tests failed on ${{ github.ref_name }}
            Success Rate: ${{ env.SUCCESS_RATE }}%
            Failed Tests: ${{ env.FAILED_TESTS }}/${{ env.TOTAL_TESTS }}
            View results: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  security-scan:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Security scan for OAuth implementation
        run: |
          echo "Scanning OAuth implementation for security issues..."

          # Check for hardcoded secrets
          if grep -r "client_secret\|access_token\|refresh_token" apps/web/tests/ --exclude-dir=node_modules --exclude="*.md" | grep -v "mock\|test\|example"; then
            echo "❌ Potential hardcoded secrets found in OAuth tests"
            exit 1
          fi

          # Check for proper mock usage
          if ! grep -q "USE_MOCK_OAUTH" apps/web/tests/config/test-env.ts; then
            echo "❌ Mock OAuth configuration not found"
            exit 1
          fi

          # Validate PKCE implementation
          if ! grep -q "code_challenge.*S256" apps/web/tests/helpers/oauth-mock.ts; then
            echo "❌ PKCE S256 method not properly implemented in mocks"
            exit 1
          fi

          echo "✅ OAuth security scan passed"

      - name: Validate OAuth test coverage
        working-directory: ${{ env.WORKING_DIRECTORY }}
        run: |
          echo "Validating OAuth test coverage..."

          # Check that critical OAuth scenarios are covered
          required_scenarios=(
            "oauth.*login"
            "pkce"
            "session.*persistence"
            "error.*handling"
            "network.*failure"
            "security.*validation"
          )

          test_files="tests/e2e/auth.spec.ts tests/e2e/oauth-error-scenarios.spec.ts"

          for scenario in "${required_scenarios[@]}"; do
            if ! grep -qi "$scenario" $test_files; then
              echo "❌ Required OAuth scenario not found: $scenario"
              exit 1
            fi
          done

          echo "✅ OAuth test coverage validation passed"